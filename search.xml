<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>blog项目计划书&amp;可行性研究</title>
    <url>/2021/04/12/crawler-init/</url>
    <content><![CDATA[<h1 id="方尖碑历史博物馆项目可行性研究报告"><a href="#方尖碑历史博物馆项目可行性研究报告" class="headerlink" title="方尖碑历史博物馆项目可行性研究报告"></a><del>方尖碑历史博物馆项目可行性研究报告</del></h1><p>实际上是第一次随笔，自重新开始写hexo博客的第一篇随笔</p>
<span id="more"></span>

<h2 id="写在前面-amp-必要性"><a href="#写在前面-amp-必要性" class="headerlink" title="写在前面&amp;必要性"></a>写在前面&amp;必要性</h2><p>​    有些话人们常说，喜欢的事儿和擅长的事儿是两码事，若能够靠喜欢且擅长的事儿谋生当属人生中的一大幸事儿，我的研究生导师当属这样的人，喜欢写论文，擅长写论文，无时无刻在写论文，而且通过写论文在学术圈获得了一定的成就和地位；</p>
<p>​    我是发自内心的敬佩这种人的，近乎自负的自信，超高的工作效率，层出不穷的新点子，每时每刻都沉浸在心流状态中，也导致了我研究生阶段悲剧的开始，进入了我不熟悉的领域，成了一名从来没有考虑过在会计类行业就业的会计专业研究生；</p>
<p>​    而我自认为是没有办法达到他这种程度的，出身于西电，务实的作风和近乎病态的技术崇拜已经成为我抹不去特征，要我做这类我看来不会有任何贡献，内卷化的推手的工作，我是发自内心的厌恶与厌倦，在持续了半个学期的科研尝试后，我近乎狼狈的逃离了这个地方，圣洁又肮脏的地方，去寻求自救，逃离会计，逃离商科；</p>
<p>​    我尝试过很多，报过白熊的VIP课程，报过腾讯的未来空间站计划，在我奇奇怪怪的技能栈以及相关经历的缺乏的加持下，毫无悬念的落选了，腾讯的HR在这方面真的做的特别好，完全照顾了每个前来报名的应试者的体验，可最让我在意的，无疑还是那句您在游戏行业的浸润度不够；</p>
<p>​    这件事情也成了我完全反思自己技能栈的源头之一，我想去哪儿，我的竞争力又在哪儿，于是我又找回了我原来想要尝试的部分，并想要尝试重启自己的blog，也因此写下了这个奇奇怪怪的，充满中二气息的标题，总结自己的求职尝试和努力部分，并作为自己作品的暂存部分，这类文章也就由此而生；</p>
<p>​    感谢这些可能没人会看的废话，是这些废话激励着我前进，愿正在写这篇随笔和记录的我，以及正在看的你万事胜意，永远年轻，永远在路上；</p>
<blockquote>
<p>本处使用过的markdown语法只有两个要点，目录[TOC]，以及大标题# 一级大标题 ## 二级大标题等。。。。</p>
</blockquote>
<p>​    原有的项目为junbofans.github.io，上次更新为2年前，因此现在有将其重启的打算</p>
<h2 id="项目验收标准："><a href="#项目验收标准：" class="headerlink" title="项目验收标准："></a>项目验收标准：</h2><p>1.作为面试前的标准</p>
<p>2.做实际项目的时候会想起这个项目的类似经验，回头在该项目中寻找，更新解决方案</p>
<h2 id="项目包含内容："><a href="#项目包含内容：" class="headerlink" title="项目包含内容："></a>项目包含内容：</h2><p>​    该项目作为产，运，数分的求职准备记录，至少该包含的内容应有：</p>
<p>​    1.产品相关教程贴</p>
<p>​    2.运营相关教程贴</p>
<p>​    3.数分相关教程贴</p>
<p>​    4.作品集</p>
<p>​    5.面经，求职经验</p>
<p>​    6.随笔【未完成的作品集，或者说开的坑】</p>
<p>​    7.blog运维</p>
<p>​    8.and so on</p>
]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>立项文件</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始的爬虫【1】</title>
    <url>/2021/04/13/webcrawler-0/</url>
    <content><![CDATA[<p>本篇主要介绍的内容为，技术学习路线，优秀教程等</p>
<span id="more"></span>

<h2 id="技术学习路线"><a href="#技术学习路线" class="headerlink" title="技术学习路线"></a>技术学习路线</h2><h2 id="优秀教程"><a href="#优秀教程" class="headerlink" title="优秀教程"></a>优秀教程</h2><h3 id="网课类"><a href="#网课类" class="headerlink" title="网课类"></a>网课类</h3><p>1.<a href="https://www.bilibili.com/video/BV12E411A7ZQ">Python爬虫基础5天速成（2021全新合集）Python入门+数据可视化</a></p>
<blockquote>
<p>成都工业大学李巍老师在疫情期间录制的，面向求职的爬虫教程，用request，bs4，re等库完成的，以豆瓣top250为例子的网课类教程；</p>
</blockquote>
<h3 id="文档类"><a href="#文档类" class="headerlink" title="文档类"></a>文档类</h3><p>1.<a href="https://docs.python-requests.org/zh_CN/latest/">requests官方文档</a></p>
<p>2.<a href="https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/">beautifulsoup官方文档</a></p>
<blockquote>
<p>之前我也迷恋教程，直到后来我开始直接看文档</p>
<p>​                                                                                                    ——-我自己说的</p>
</blockquote>
<h3 id="项目类"><a href="#项目类" class="headerlink" title="项目类"></a>项目类</h3><p>1.<a href="https://github.com/facert/awesome-spider">总和类项目，awesome-spyder</a></p>
<blockquote>
<p> 这个项目按照拼音引索对收集到的爬虫进行了归类整理，是较为优秀的项目集合，有些项目在爬虫之后甚至做了前端应用来实现数据可视化；</p>
</blockquote>
<p>2.爬取豆瓣部分（别急，还在写，等着自引呢）</p>
<blockquote>
<p>豆瓣是静态网页，是最容易爬的类型，也是大家练手最常选择的项目之一，因而该项目有大量的案例，很难分析出有意思的东西，属于拿来练手的项目</p>
</blockquote>
]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始的爬虫【2】</title>
    <url>/2021/04/13/webcrawler-1/</url>
    <content><![CDATA[<p>​    这期是打算从豆瓣top250开始尝试，豆瓣属于静态网页，适合作为小白的练手项目，故从这个项目开始，本项目的最终目的是将top250中的数据保存至db文件中，供日后数据分析和可视化使用；</p>
<span id="more"></span>

<p>​    这期是打算从豆瓣top250开始尝试，爬豆瓣top250高分电影，这类题目好像在网易游戏的题目中出现过，还是存在一些玩的必要性的，由于豆瓣属于静态网页，适合作为小白的练手项目，故从这个项目开始；本项目几乎完全来源于request的官方中文文档，详见：</p>
<blockquote>
<p>requests库官方中文文档</p>
<p><a href="https://docs.python-requests.org/zh_CN/latest/user/quickstart.html#id5">https://docs.python-requests.org/zh_CN/latest/user/quickstart.html#id5</a></p>
</blockquote>
<p>​    本文档打算以面向项目的实操记录的形式来进行的，因此本项目的基本目的是能够实现目的，即能够获取豆瓣top250的数据库，能运行即可，只有在遇到的时候才会考虑用法方面的问题，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>​    该部分代表整个程序的运行顺序，程序将从这个这行开始向下运行，用来简化阅读理解的流程；并在主函数下定义一个main（）方法；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment"># there is your code</span></span><br></pre></td></tr></table></figure>

<p>​    从整个函数的运行逻辑上来看，爬虫的通用逻辑大致可以分为</p>
<ol>
<li>对网页发送请求，网站返回数据包（使用request等库）</li>
<li>对数据包进行解析（使用Beautiful Soup等库）</li>
<li>对解析出的数据进行拆包，找出自己需要的数据（使用re正则表达式）</li>
<li>对自己爬出的数据存储进行存储（存进xlsx，或者自建data base）</li>
</ol>
<h2 id="对网页发送请求："><a href="#对网页发送请求：" class="headerlink" title="对网页发送请求："></a>对网页发送请求：</h2><p>​    在对网页发送请求时，最常用的库为request库，该库作为项目中第一个介绍的工具形项目，未来是否会有使用工具上的更新暂时还不清楚，属于和大家一起学习探索的过程；</p>
<img src="https://docs.python-requests.org/zh_CN/latest/_static/requests-sidebar.png" alt="requests-sidebar.png (1020×1308)" style="zoom: 33%;" />

<blockquote>
<p>Requests 唯一的一个<strong>非转基因</strong>的 Python HTTP 库，人类可以安全享用。</p>
<p><strong>警告</strong>：非专业使用其他 HTTP 库会导致危险的副作用，包括：安全缺陷症、冗余代码症、重新发明轮子症、啃文档症、抑郁、头疼、甚至死亡。</p>
</blockquote>
<p>​    在最初的项目中并不需要接触太深的request库的内容，将会根据项目，或者实操中遇到的问题回头介绍，先从每个爬虫流程的第一步，发送请求开始介绍吧；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">baseurl = <span class="string">&quot;https://movie.douban.com/top250&quot;</span></span><br><span class="line">r = requests.get(baseurl)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>得到的结果是：&lt;Response [418]&gt;，一个叫做418的返回对象，对象的类型是Response对象；</p>
<p>【418】我是个茶壶，我煮不了咖啡，是你被豆瓣网识别出来是爬虫程序，被拦截了，需要做一定的更改；</p>
<p>对于豆瓣的爬取策略，最简单的方式是封装一个header头文件，告诉豆瓣你是正常的浏览器，将在下一小节，包装头文件中加以介绍；</p>
</blockquote>
<h2 id="包装头文件"><a href="#包装头文件" class="headerlink" title="包装头文件"></a>包装头文件</h2><blockquote>
<h2 id="定制请求头"><a href="#定制请求头" class="headerlink" title="定制请求头"></a>定制请求头</h2><p>如果你想为请求添加 HTTP 头部，只要简单地传递一个 <code>dict</code> 给 <code>headers</code> 参数就可以了。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">baseurl = <span class="string">&quot;https://movie.douban.com/top250&quot;</span></span><br><span class="line"><span class="comment"># 豆瓣作为较为简单的反爬机制，设置的应该是之检查了user agent这一个参数，伪装该参数使用的格式见为</span></span><br><span class="line"><span class="comment"># headers = &#123;&quot;user-agent&quot;:&quot;....内容&quot;&#125;</span></span><br><span class="line">headers = &#123;<span class="string">&quot;user-agent&quot;</span>:<span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36 Edg/89.0.774.76&quot;</span>&#125;</span><br><span class="line"><span class="comment"># 以上agent中的内容来源于浏览器，f12，刷新，header参数，user-agent部分；</span></span><br><span class="line">r = requests.get(baseurl,headers = headers)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br><span class="line"><span class="comment"># 直接打印r的话会获得一个&lt;class &#x27;requests.models.Response&#x27;&gt;对象</span></span><br><span class="line"><span class="built_in">print</span>(r.headers)</span><br><span class="line"><span class="comment"># 打印r.headers以及r.text 则可以获得其中的头文件部分，以及内容部分；</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>此时得到的状态参数为&lt;200&gt;，该状态码的意思是成功处理了请求，伪装头文件之后，可以发现豆瓣不再拦截我们的访问请求，说自己是个茶壶了，对于我们得到的 &lt;class ‘requests.models.Response’&gt; 对象，我们下一步该做的就是响应其内容了；</p>
</blockquote>
<h2 id="响应内容"><a href="#响应内容" class="headerlink" title="响应内容"></a>响应内容</h2><blockquote>
<p>Requests 会自动解码来自服务器的内容。大多数 unicode 字符集都能被无缝地解码。</p>
<p>请求发出后，Requests 会基于 HTTP 头部对响应的编码作出有根据的推测。<strong>当你访问 <code>r.text</code> 之时，Requests 会使用其推测的文本编码(这还不够酷吗）</strong>。你可以找出 Requests 使用了什么编码，并且能够使用 <code>r.encoding</code> 属性来改变它：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;&gt; r.encoding</span><br><span class="line">&gt;<span class="string">&quot;utf-8&quot;</span></span><br><span class="line">&gt;&gt;&gt;&gt; r.encoding = <span class="string">&quot;ISO-8859-1&quot;</span></span><br></pre></td></tr></table></figure>

<p>​    但一旦改变了r的encoding属性，之后对r.text的访问就不会再自动推测编码了，而是使用你设定好的r.encoding的编码；</p>
</blockquote>
<p>​    打印一下获取到的响应的内容，截取获得一小部分如下所示：(输出空间有限，导致没有办法做到很完美的截取，所以只作为实例展示)：</p>
<blockquote>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;pic&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">em</span> <span class="attr">class</span>=<span class="string">&quot;&quot;</span>&gt;</span>9<span class="tag">&lt;/<span class="name">em</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://movie.douban.com/subject/3541415/&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">img</span> <span class="attr">width</span>=<span class="string">&quot;100&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;盗梦空间&quot;</span> <span class="attr">src</span>=<span class="string">&quot;https://img2.doubanio.com/view/photo/s_ratio_poster/public/p2616355133.jpg&quot;</span> <span class="attr">class</span>=<span class="string">&quot;&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;info&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;hd&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://movie.douban.com/subject/3541415/&quot;</span> <span class="attr">class</span>=<span class="string">&quot;&quot;</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;title&quot;</span>&gt;</span>盗梦空间<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;title&quot;</span>&gt;</span><span class="symbol">&amp;nbsp;</span>/<span class="symbol">&amp;nbsp;</span>Inception<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;other&quot;</span>&gt;</span><span class="symbol">&amp;nbsp;</span>/<span class="symbol">&amp;nbsp;</span>潜行凶间(港)  /  全面启动(台)<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;playable&quot;</span>&gt;</span>[可播放]<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;bd&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;&quot;</span>&gt;</span></span><br><span class="line">                    导演: 克里斯托弗·诺兰 Christopher Nolan<span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span>主演: 莱昂纳多·迪卡普里奥 Le...<span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">                    2010<span class="symbol">&amp;nbsp;</span>/<span class="symbol">&amp;nbsp;</span>美国 英国<span class="symbol">&amp;nbsp;</span>/<span class="symbol">&amp;nbsp;</span>剧情 科幻 悬疑 冒险</span><br><span class="line">                <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;star&quot;</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;rating45-t&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;rating_num&quot;</span> <span class="attr">property</span>=<span class="string">&quot;v:average&quot;</span>&gt;</span>9.3<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">span</span> <span class="attr">property</span>=<span class="string">&quot;v:best&quot;</span> <span class="attr">content</span>=<span class="string">&quot;10.0&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">span</span>&gt;</span>1695611人评价<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                    <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;quote&quot;</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;inq&quot;</span>&gt;</span>诺兰给了我们一场无法盗取的梦。<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>

</blockquote>
<p>​    从上述文件的格式来看属于较为明显的html格式文件，而我们使用r.text将其打开，展现在我们面前的这部分则类似与一个文本文档，可以直接使用正则表达式的方法对内部所需内容进行提取，当然html格式的文件自带的，标准且严格的格式是否能够让我们通过标签进行检索，不用建立新的正则表达式呢？答案是肯定的，因此我们需要引入一个全新且好用的库，bs4（靓汤？；</p>
<h2 id="简化查询"><a href="#简化查询" class="headerlink" title="简化查询"></a>简化查询</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(r.text,<span class="string">&quot;html.parser&quot;</span>) <span class="comment"># html格式的内容 或者是text格式的内容</span></span><br></pre></td></tr></table></figure>

<p>​    由此我们便生成了一个BS4对象，便于我们查找，该BS4对象可以看作一个嵌套的键值对；例如键为</li>而值则为子一级的html格式文档，在这个子一级的html格式文档之中，键为<div class="item">等，值则为更子一级的html格式文档，（或者链表的解释会更好？）</p>
<p><img src="C:\Users\yubari\AppData\Roaming\Typora\typora-user-images\image-20210415110204965.png" alt="image-20210415110204965"></p>
<p>​    在构筑了靓汤对象之后，下一步就是提取对象中的内容，保存在数据库中了，而整个bs4对象中我们所需的内容总是有限的，首先就可以限制在红框内的内容；除此之外，也并不是所有的红框内的内容都是需要，我们选中一个单对象来看看里面到底有多少内容：</p>
<p><img src="C:\Users\yubari\AppData\Roaming\Typora\typora-user-images\image-20210415111059871.png" alt="image-20210415111059871"></p>
<p>​    而我们需要的内容相比之下，并不会有那么多div，li，span之类，也不需要希望让人自由这类短评价；在下一步我们就需要将所需内容提取出来，使用正则匹配或者靓汤自带方法来提取所需内容；</p>
<p><img src="C:\Users\yubari\AppData\Roaming\Typora\typora-user-images\image-20210415140033582.png" alt="image-20210415140033582"></p>
<p>​    <del>导演，主演，cast等可能并不会分析出什么有价值的内容，故本阶段主要以上述红线部分的内容为主建立db，片名，年份，国别，类型，人数，分数六种来建立数据库，英文名无所谓了，还是以最被熟知的中文名为索引建立数据库。</del></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pre = soup.find_all(class_ = <span class="string">&quot;item&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">name = pre.find_all(class_ = <span class="string">&quot;title&quot;</span>)[<span class="number">0</span>].text</span><br></pre></td></tr></table></figure>

<p>​    为了便于后续操作，先将第一个对象(特点是有一个<div class = "item">标签)提取出来，再从该标签中提取出片名（片名的特点是有<div class = "title">标签），之后再将该标签内的第一个text保存就获取了片名；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_star</span>(<span class="params">soup,j</span>):</span></span><br><span class="line">    pre = soup.find_all(class_ = <span class="string">&quot;item&quot;</span>)[j]</span><br><span class="line">    findtext = pre.find_all(class_ = <span class="string">&quot;star&quot;</span>)[<span class="number">0</span>].text</span><br><span class="line">    people = [x <span class="keyword">for</span> x <span class="keyword">in</span> findtext.splitlines() <span class="keyword">if</span> x!=<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> people</span><br></pre></td></tr></table></figure>

<p>​    在获取影片的评分内容的时候，尝试了直接对tag提取内容，结果是可以将所有的text内容全部获取，对于没有内容的部分貌似会产生一个/n换行符，或者本身就有一个换行符存在，因而使用了str类型自带的splitlines()方法将内容转换为列表，并再对列表遍历排除空元素获得了最终的结果，分数，和评价人数；到此我们就已经得到了三个数据，片名，分数，和评价人数，剩下年份，类型，国三个数据需要查询；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_type</span>(<span class="params">soup,j</span>):</span></span><br><span class="line">    pre = soup.find_all(class_ = <span class="string">&quot;item&quot;</span>)[j]</span><br><span class="line">    g_type = pre.find_all(class_ = <span class="string">&quot;bd&quot;</span>)[<span class="number">0</span>].text.split()</span><br><span class="line">    <span class="keyword">return</span> g_type</span><br><span class="line"></span><br><span class="line">soup = get_page(<span class="number">0</span>);</span><br><span class="line"><span class="built_in">print</span>(get_type(soup,<span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<p>​    当继续使用之前get_star的方法来寻找内容的时候，得出了还算有些意思的结果；</p>
<blockquote>
<p>[‘导演:’, ‘弗兰克·德拉邦特’, ‘Frank’, ‘Darabont’, ‘主演:’, ‘蒂姆·罗宾斯’, ‘Tim’, ‘Robbins’, ‘/…’, ‘1994’, ‘/‘, ‘美国’, ‘/‘, ‘犯罪’, ‘剧情’, ‘9.7’, ‘2329719人评价’, ‘希望让人自由。’]</p>
<p>上述结果中看上去是所有的内容都存在，然而，对这部分内容的分割活动会由于部分内容的缺失，例如最后的评语也不是每一个item都有的，分割方法即不能使用位置定位，也不能用/定位；可以考虑使用其他的方法，例如使用正则表达式；</p>
</blockquote>
<p><img src="C:\Users\yubari\AppData\Roaming\Typora\typora-user-images\image-20210415173713266.png" alt="image-20210415173713266"></p>
]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>教程</tag>
      </tags>
  </entry>
</search>
